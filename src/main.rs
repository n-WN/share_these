use axum::{
    extract::{ConnectInfo, Path, State},
    http::{header::{CONTENT_TYPE, CONTENT_LENGTH, RANGE, ACCEPT_RANGES, CONTENT_RANGE}, StatusCode, HeaderMap},
    response::{Html, IntoResponse, Response},
    routing::get,
    Router,
    body::Body,
};
use std::net::SocketAddr;
use std::{path::PathBuf, sync::Arc, io::SeekFrom};
use tokio::fs::{self, File};
use tokio::io::{AsyncSeekExt, AsyncRead, AsyncReadExt};
use tower_http::trace::TraceLayer;
use tracing::{error, info, Level};
use tracing_subscriber::FmtSubscriber;
use anyhow::{Context, Result, anyhow};
use tokio_util::io::ReaderStream;
use std::cmp::min;
use clap::Parser;
use tower::limit::ConcurrencyLimitLayer;
use moka::future::Cache;

mod templates;
use templates::render_file_list;

// å‘½ä»¤è¡Œå‚æ•°å®šä¹‰
#[derive(Parser)]
#[command(
    name = PKG_NAME,
    author = PKG_AUTHORS,
    version = PKG_VERSION,
    about = PKG_DESCRIPTION,
    long_about = "åˆ†äº«å½“å‰ç›®å½•(åŒ…æ‹¬å­ç›®å½•)ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"
)]
struct Args {
    /// æœåŠ¡å™¨ç»‘å®šçš„ç«¯å£
    #[arg(short, long, default_value_t = 3000)]
    port: u16,

    /// æœåŠ¡å™¨ç»‘å®šçš„ç½‘å¡åœ°å€
    #[arg(short, long, default_value = "0.0.0.0")]
    host: String,
}

// ä½œè€…ä¿¡æ¯ç»“æ„ä½“
#[derive(Clone)]
pub struct Author {
    pub name: String,
    pub email: Option<String>,
    pub website: Option<String>,
    pub github: Option<String>,
}

// ç¼–è¯‘æ—¶å¸¸é‡ï¼Œä»Cargo.tomlè¯»å–
const PKG_NAME: &str = env!("CARGO_PKG_NAME");
const PKG_VERSION: &str = env!("CARGO_PKG_VERSION");
const PKG_AUTHORS: &str = env!("CARGO_PKG_AUTHORS");
const PKG_DESCRIPTION: &str = env!("CARGO_PKG_DESCRIPTION");
const PKG_REPOSITORY: &str = env!("CARGO_PKG_REPOSITORY");

// åº”ç”¨çŠ¶æ€ï¼Œå­˜å‚¨æ ¹ç›®å½•è·¯å¾„å’Œä½œè€…ä¿¡æ¯
#[derive(Clone)]
struct AppState {
    root_dir: Arc<PathBuf>,
    author: Author,
    cache: Cache<String, Vec<u8>>,
}

// æœ€å¤§ç¼“å­˜æ–‡ä»¶å¤§å° (1MB)
const MAX_CACHE_FILE_SIZE: u64 = 1024 * 1024;

#[tokio::main]
async fn main() -> Result<()> {
    // è§£æå‘½ä»¤è¡Œå‚æ•°
    let args = Args::parse();

    // åˆå§‹åŒ–æ—¥å¿—
    let subscriber = FmtSubscriber::builder()
        .with_max_level(Level::INFO)
        .with_target(false)
        .finish();

    tracing::subscriber::set_global_default(subscriber)
        .context("Failed to set global tracing subscriber")?;

    // è¾“å‡ºé¡¹ç›®ä¿¡æ¯
    println!("----------------------------------------");
    println!("ğŸ“‚ {} v{}", PKG_NAME, PKG_VERSION);
    println!("ğŸ“ {}", PKG_DESCRIPTION);
    println!("ğŸ‘¤ {}", PKG_AUTHORS);
    println!("ğŸ”— {}", PKG_REPOSITORY);
    println!("----------------------------------------");

    // è·å–å·¥ä½œç›®å½•ä½œä¸ºæ ¹ç›®å½•
    let root_dir = std::env::current_dir()
        .context("Failed to get current working directory")?;
    
    // åˆ›å»ºä½œè€…ä¿¡æ¯
    let author = Author {
        name: PKG_AUTHORS.split(',').next().unwrap_or("æ–‡ä»¶åˆ†äº«å·¥å…·").trim().to_string(),
        email: None,  // ä¸å†æ˜¾ç¤ºé‚®ç®±
        website: None,
        github: Some(PKG_REPOSITORY.to_string()),
    };

    // åˆ›å»ºç¼“å­˜
    let cache = Cache::new(100); // ç¼“å­˜æœ€å¤š100ä¸ªæ–‡ä»¶
    
    let state = AppState {
        root_dir: Arc::new(root_dir),
        author,
        cache,
    };

    // æ„å»ºåº”ç”¨ç¨‹åº
    let app = Router::new()
        .route("/", get(list_files))
        // ä½¿ç”¨ {*path} æ¥æ•è·æ‰€æœ‰è·¯å¾„æ®µï¼ŒåŒ…æ‹¬åµŒå¥—è·¯å¾„
        .route("/files/{*path}", get(serve_file))
        .layer(TraceLayer::new_for_http())
        .layer(ConcurrencyLimitLayer::new(64)) // é™åˆ¶æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ä¸º64
        .with_state(state.clone()); // https://github.com/n-WN/share_these/blob/80c267ed15729df5daadb4b480e05cf120d3abc7/src/main.rs#L135

    // ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„åœ°å€å’Œç«¯å£
    let addr = format!("{}:{}", args.host, args.port);
    let listener = tokio::net::TcpListener::bind(&addr)
        .await
        .context(format!("Failed to bind to address {}", addr))?;
    
    // å¦‚æœä¸»æœºæ˜¯0.0.0.0ï¼Œæ˜¾ç¤ºæ—¶ç”¨localhostæ–¹ä¾¿ç”¨æˆ·è®¿é—®
    let display_host = if args.host == "0.0.0.0" { "localhost" } else { &args.host };
    info!("Server running at http://{}:{}", display_host, args.port);
    
    // ç»Ÿä¸€ä½¿ç”¨state.root_dirè€Œä¸æ˜¯å•ç‹¬æ‰“å°root_dir
    println!("é¡¹ç›®æ ¹ç›®å½•: {}", state.root_dir.display());
    println!("è®¿é—®åœ°å€: http://{}:{}", display_host, args.port);
    println!("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡");

    axum::serve(
        listener,
        app.into_make_service_with_connect_info::<SocketAddr>(),
    )
        .await
        .context("Server error")?;

    Ok(())
}

// åˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
async fn list_files(
    ConnectInfo(addr): ConnectInfo<SocketAddr>,
    State(state): State<AppState>,
) -> Response {
    let dir = &*state.root_dir;

    match read_directory(dir, None).await {
        Ok((folders, files)) => {
            info!(ip = %addr.ip(), "File list requested for root directory");
            render_file_list(folders, files, Some("/"), &state.author)
        }
        Err(e) => {
            error!(ip = %addr.ip(), "Failed to read directory: {:#}", e);
            Html(format!(
                r#"<html><body><h1>Error</h1><p>{:#}</p></body></html>"#,
                e
            ))
                .into_response()
        }
    }
}

// æä¾›æ–‡ä»¶ä¸‹è½½
async fn serve_file(
    Path(path): Path<String>,
    ConnectInfo(addr): ConnectInfo<SocketAddr>,
    State(state): State<AppState>,
    headers: HeaderMap,
) -> Response {
    // æ£€æŸ¥è·¯å¾„å®‰å…¨æ€§
    if path.contains("..") {
        error!(ip = %addr.ip(), "å®‰å…¨é—®é¢˜: è·¯å¾„åŒ…å«'..'åºåˆ—: {}", path);
        return StatusCode::BAD_REQUEST.into_response();
    }

    let full_path = state.root_dir.join(&path);

    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if !full_path.exists() {
        error!(ip = %addr.ip(), "File not found: {:?}", full_path);
        return StatusCode::NOT_FOUND.into_response();
    }

    // å¦‚æœæ˜¯ç›®å½•ï¼Œåˆ™æ˜¾ç¤ºç›®å½•å†…å®¹
    if full_path.is_dir() {
        match read_directory(&full_path, Some(&path)).await {
            Ok((folders, files)) => {
                info!(ip = %addr.ip(), "Directory listing for: {}", path);
                render_file_list(folders, files, Some(&path), &state.author)
            }
            Err(e) => {
                error!(ip = %addr.ip(), "Failed to read directory: {:#}", e);
                Html(format!(
                    r#"<html><body><h1>Error</h1><p>{:#}</p></body></html>"#,
                    e
                ))
                    .into_response()
            }
        }
    } else {
        // æ£€æŸ¥ç¼“å­˜ - ä½¿ç”¨awaitç­‰å¾…Futureå®Œæˆ
        if let Some(cached_data) = state.cache.get(&path).await {
            info!(ip = %addr.ip(), "Serving cached file: {:?}", full_path);
            return Response::builder()
                .status(StatusCode::OK)
                .header(CONTENT_TYPE, determine_content_type(&full_path))
                .header(CONTENT_LENGTH, cached_data.len().to_string())
                .body(Body::from(cached_data))
                .unwrap()
                .into_response();
        }

        // æµå¼ä¼ è¾“æ–‡ä»¶å†…å®¹
        match stream_file(&full_path, &path, &headers, addr.ip().to_string(), &state.cache).await {
            Ok(response) => response,
            Err(e) => {
                error!(ip = %addr.ip(), "Failed to stream file: {:?}, error: {:#}", full_path, e);
                match e.downcast_ref::<std::io::Error>() {
                    Some(io_err) if io_err.kind() == std::io::ErrorKind::PermissionDenied => {
                        StatusCode::FORBIDDEN.into_response()
                    },
                    Some(io_err) if io_err.kind() == std::io::ErrorKind::NotFound => {
                        StatusCode::NOT_FOUND.into_response()
                    },
                    _ => StatusCode::INTERNAL_SERVER_ERROR.into_response(),
                }
            }
        }
    }
}

// æµå¼ä¼ è¾“æ–‡ä»¶
async fn stream_file(
    path: &PathBuf, 
    cache_key: &str,
    headers: &HeaderMap, 
    client_ip: String, 
    cache: &Cache<String, Vec<u8>>
) -> Result<Response> {
    // è·å–æ–‡ä»¶å…ƒæ•°æ®
    let metadata = fs::metadata(path).await
        .with_context(|| format!("Failed to get metadata for {:?}", path))?;
    let file_size = metadata.len();
    
    // ç¡®å®šå†…å®¹ç±»å‹
    let content_type = determine_content_type(path);
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯èŒƒå›´è¯·æ±‚
    if let Some(range_header) = headers.get(RANGE) {
        return handle_range_request(path, range_header, file_size, content_type, client_ip).await;
    }
    
    // æ ‡å‡†è¯·æ±‚ - æµå¼ä¼ è¾“æ•´ä¸ªæ–‡ä»¶
    info!(ip = %client_ip, "Streaming full file: {:?}", path);
    
    // å¦‚æœæ–‡ä»¶å°äºé˜ˆå€¼ï¼Œå…ˆè¯»å…¥å†…å­˜ç„¶åç¼“å­˜å¹¶è¿”å›
    if file_size <= MAX_CACHE_FILE_SIZE {
        // æ·»åŠ æ—¥å¿—ï¼Œè®°å½•å“ªäº›æ–‡ä»¶è¢«ç¼“å­˜
        info!(ip = %client_ip, "Caching small file: {:?} ({} bytes)", path, file_size);
        
        let mut file = File::open(path).await
            .with_context(|| format!("Failed to open file {:?}", path))?;
        
        let mut buffer = Vec::with_capacity(file_size as usize);
        file.read_to_end(&mut buffer).await
            .with_context(|| format!("Failed to read file {:?}", path))?;
        
        // ç¼“å­˜æ–‡ä»¶å†…å®¹
        cache.insert(cache_key.to_string(), buffer.clone()).await;
        
        // è®¾ç½®å“åº”å¤´
        let mut response_headers = HeaderMap::new();
        response_headers.insert(CONTENT_TYPE, content_type.parse().unwrap());
        response_headers.insert(CONTENT_LENGTH, file_size.to_string().parse().unwrap());
        response_headers.insert(ACCEPT_RANGES, "bytes".parse().unwrap());
        
        return Ok((StatusCode::OK, response_headers, Body::from(buffer)).into_response());
    }
    
    // å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æµå¼ä¼ è¾“
    let file = File::open(path).await
        .with_context(|| format!("Failed to open file {:?}", path))?;
    
    // åˆ›å»ºæµï¼Œä½¿ç”¨8KBçš„ç¼“å†²åŒº
    let reader_stream = ReaderStream::with_capacity(file, 8 * 1024);
    let body = Body::from_stream(reader_stream);
    
    // è®¾ç½®å“åº”å¤´
    let mut response_headers = HeaderMap::new();
    response_headers.insert(CONTENT_TYPE, content_type.parse().unwrap());
    response_headers.insert(CONTENT_LENGTH, file_size.to_string().parse().unwrap());
    response_headers.insert(ACCEPT_RANGES, "bytes".parse().unwrap());
    
    Ok((StatusCode::OK, response_headers, body).into_response())
}

// å¤„ç†HTTP Rangeè¯·æ±‚
async fn handle_range_request(
    path: &PathBuf,
    range_header: &axum::http::HeaderValue,
    file_size: u64,
    content_type: &'static str,
    client_ip: String
) -> Result<Response> {
    // è§£æRangeå¤´ (æ ¼å¼: "bytes=start-end")
    let range_str = range_header.to_str().map_err(|_| anyhow!("Invalid range header"))?;
    
    if !range_str.starts_with("bytes=") {
        return Err(anyhow!("Unsupported range unit"));
    }
    
    let range_parts: Vec<&str> = range_str["bytes=".len()..].split('-').collect();
    if range_parts.len() != 2 {
        return Err(anyhow!("Invalid range format"));
    }
    
    // è§£æstartå’Œendä½ç½®
    let start = if range_parts[0].is_empty() { 
        0 
    } else { 
        range_parts[0].parse::<u64>().map_err(|_| anyhow!("Invalid range start"))? 
    };
    
    let end = if range_parts[1].is_empty() { 
        file_size - 1 
    } else { 
        range_parts[1].parse::<u64>().map_err(|_| anyhow!("Invalid range end"))? 
    };
    
    // éªŒè¯èŒƒå›´æœ‰æ•ˆæ€§å¹¶æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    if start > end {
        return Err(anyhow!("Invalid range: start ({}) > end ({})", start, end));
    }
    
    if start >= file_size {
        return Err(anyhow!("Range start ({}) exceeds file size ({})", start, file_size));
    }
    
    // èŒƒå›´é•¿åº¦å’Œå®é™…ç»“æŸä½ç½®
    let end = min(end, file_size - 1);
    let content_length = end - start + 1;
    
    info!(ip = %client_ip, "Range request: {:?}, bytes {}-{}/{}", path, start, end, file_size);
    
    // æ‰“å¼€æ–‡ä»¶å¹¶è·³åˆ°èµ·å§‹ä½ç½®
    let mut file = File::open(path).await
        .with_context(|| format!("Failed to open file {:?}", path))?;
    
    file.seek(SeekFrom::Start(start)).await
        .with_context(|| format!("Failed to seek to position {} in file {:?}", start, path))?;
    
    // åˆ›å»ºè‡ªå®šä¹‰æµä»¥é™åˆ¶è¯»å–çš„å­—èŠ‚æ•°
    let bounded_file = BoundedReader::new(file, content_length);
    let reader_stream = ReaderStream::with_capacity(bounded_file, 8 * 1024); // è®¾ç½®8KBç¼“å†²åŒº
    let body = Body::from_stream(reader_stream);
    
    // è®¾ç½®å“åº”å¤´
    let mut response_headers = HeaderMap::new();
    response_headers.insert(CONTENT_TYPE, content_type.parse().unwrap());
    response_headers.insert(CONTENT_LENGTH, content_length.to_string().parse().unwrap());
    response_headers.insert(
        CONTENT_RANGE, 
        format!("bytes {}-{}/{}", start, end, file_size).parse().unwrap()
    );
    response_headers.insert(ACCEPT_RANGES, "bytes".parse().unwrap());
    
    Ok((StatusCode::PARTIAL_CONTENT, response_headers, body).into_response())
}

// æœ‰ç•Œè¯»å–å™¨ - é™åˆ¶è¯»å–çš„å­—èŠ‚æ•°
struct BoundedReader<R> {
    inner: R,
    remaining: u64,
}

impl<R> BoundedReader<R> {
    fn new(inner: R, limit: u64) -> Self {
        Self {
            inner,
            remaining: limit,
        }
    }
}

impl<R: AsyncRead + Unpin> AsyncRead for BoundedReader<R> {
    fn poll_read(
        mut self: std::pin::Pin<&mut Self>,
        cx: &mut std::task::Context<'_>,
        buf: &mut tokio::io::ReadBuf<'_>,
    ) -> std::task::Poll<std::io::Result<()>> {
        // å¦‚æœæ²¡æœ‰å‰©ä½™å­—èŠ‚è¦è¯»å–ï¼Œè¿”å›EOF
        if self.remaining == 0 {
            return std::task::Poll::Ready(Ok(()));
        }

        // é™åˆ¶è¯»å–ç¼“å†²åŒºå¤§å°
        let max_read = std::cmp::min(self.remaining as usize, buf.remaining());
        let mut limited_buf = tokio::io::ReadBuf::new(buf.initialize_unfilled_to(max_read));
        
        // è¯»å–åˆ°æœ‰é™çš„ç¼“å†²åŒº
        match AsyncRead::poll_read(std::pin::Pin::new(&mut self.inner), cx, &mut limited_buf) {
            std::task::Poll::Ready(Ok(())) => {
                let n = limited_buf.filled().len();
                buf.advance(n);
                self.remaining -= n as u64;
                std::task::Poll::Ready(Ok(()))
            }
            other => other,
        }
    }
}

// è¾…åŠ©å‡½æ•°ï¼šç¡®å®šå†…å®¹ç±»å‹
fn determine_content_type(path: &PathBuf) -> &'static str {
    match path.extension().and_then(|e| e.to_str()) {
        Some("html") | Some("htm") => "text/html",
        Some("css") => "text/css",
        Some("js") => "application/javascript",
        Some("json") => "application/json",
        Some("png") => "image/png",
        Some("jpg") | Some("jpeg") => "image/jpeg",
        Some("gif") => "image/gif",
        Some("svg") => "image/svg+xml",
        Some("pdf") => "application/pdf",
        Some("txt") | Some("md") => "text/plain",
        _ => "application/octet-stream",
    }
}

// è¾…åŠ©å‡½æ•°ï¼šè¯»å–ç›®å½•å†…å®¹
async fn read_directory(
    dir: &PathBuf,
    path_prefix: Option<&String>,
) -> Result<(Vec<(String, String, u64)>, Vec<(String, String, u64)>)> {
    let mut entries = fs::read_dir(dir)
        .await
        .with_context(|| format!("Failed to read directory {:?}", dir))?;

    let mut files = Vec::new();
    let mut folders = Vec::new();

    while let Some(entry) = entries.next_entry()
        .await
        .with_context(|| format!("Failed to read directory entry in {:?}", dir))?
    {
        let metadata = entry.metadata()
            .await
            .with_context(|| format!("Failed to read metadata for {:?}", entry.path()))?;

        let entry_path = entry.path();
        let name = entry_path
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("Unknown")
            .to_string();

        // å¤„ç†ç›¸å¯¹è·¯å¾„
        let relative_path = if let Some(prefix) = path_prefix {
            format!("{}/{}", prefix, name)
        } else {
            entry_path.strip_prefix(dir)
                .map(|p| p.to_string_lossy().to_string())
                .unwrap_or_else(|_| name.clone())
        };

        // åŒºåˆ†æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        if metadata.is_dir() {
            folders.push((name, relative_path, 0));
        } else {
            files.push((name, relative_path, metadata.len()));
        }
    }

    // æŒ‰å­—æ¯é¡ºåºæ’åº
    folders.sort_by(|a, b| a.0.cmp(&b.0));
    files.sort_by(|a, b| a.0.cmp(&b.0));

    Ok((folders, files))
}

// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
pub fn format_size(size: u64) -> String {
    const KB: u64 = 1024;
    const MB: u64 = KB * 1024;
    const GB: u64 = MB * 1024;

    if size < KB {
        format!("{} B", size)
    } else if size < MB {
        format!("{:.1} KB", size as f64 / KB as f64)
    } else if size < GB {
        format!("{:.1} MB", size as f64 / MB as f64)
    } else {
        format!("{:.1} GB", size as f64 / GB as f64)
    }
}